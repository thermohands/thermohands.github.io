<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images">
  <meta name="keywords" content="3D Hand Pose Estimation, Hand Pose Dataset, Thermal Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ThermoHands</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" /> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="icon" href="./hand_icon.png">

  <meta property="og:site_name" content="ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images" />
  <meta property="og:description" content="by anonymous authors" />
  <meta property="og:url" content="https://thermohands.github.io/" />
  <meta property="og:image" content="" />
  <meta property="og:image:secure" content="" />
  <meta property="og:video" content="" />
  <meta property="og:video:secure" content="" />
  <meta property="og:image:width" content="1280" />
  <meta property="og:image:height" content="720" />

  <meta property="article:publisher" content="https://thermohands.github.io" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images" />
  <meta name="twitter:description" content="by anonymous authors" />
  <meta name="twitter:url" content="https://thermohands.github.io/" />
  <meta name="twitter:image" content="" />
  <meta name="twitter:site" content="" />
  <meta name="twitter:card" content="player" />
  <meta name="twitter:player" content="" />
  <meta name="twitter:player:width" content="1280" />
  <meta name="twitter:player:height" content="720" />

  <script src="https://www.youtube.com/iframe_api"></script>
</head>


<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-two-thirds is-centered has-text-centered">
          <h1 class="title is-1 publication-title">ThermoHands</h1>
          <h2 class="subtitle is-2 publication-subtitle">A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Images</h2>
          <!-- <div class="is-size-4 publication-authors"> -->
            <!-- <span class="author-block"> -->
              <!-- <a href="https://zipengfu.github.io/">Zipeng Fu</a>*&nbsp;&nbsp;&nbsp;
              <a href="https://tonyzhaozh.github.io/">Tony Z. Zhao</a>*&nbsp;&nbsp;&nbsp;
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> -->
            <!-- </span> -->
          <!-- </div> -->
          </br>
          <image src="./static/images/data_capture_2.png" style="width: 100%;"></image>
          <!-- <p>
          <b>Multi-Spectral Hand Pose Dataset</b>: Data capture setup with the HMSP (customized head-mounted sensor platform) and exocentric platform recording multi-view multi-spectral images
          of two-hand actions performed by participants.
          </p> -->
          </br>
          </br>
          <em>This page provides more visualization in the format of both images and videos for our data, annotation and results. </em>
        </div>
      </div>
      <!-- <div class="columns is-centered">
        <div class="column is-two-thirds is-centered has-text-centered">
          <video download controls autoplay loop muted playsinline src="./resources/mobile-aloha.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
        </div>
      </div> -->
    </div>
  </div>
</section>
<!-- 
<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Team</h2>
    <div class="columns is-centered">
      <div class="column is-one-fifth is-centered has-text-centered">
        <a href="https://zipengfu.github.io" target="_blank" style="border-bottom: none;">
          <span class="image" ><img src="./static/images/ZipengFu.jpeg" alt="" style="width: 70%; margin-left: auto; margin-right: auto;" /></span>
        </a>
        <span style="font-weight: bold; font-size: 130%;">
          <a href="https://zipengfu.github.io" target="_blank" style="color: black;">
            Zipeng Fu
          </a>
        </span> <br>
        (project co-lead)
      </div>
      <div class="column is-one-fifth is-centered has-text-centered">
        <a href="https://tonyzhaozh.github.io/" target="_blank" style="border-bottom: none;">
          <span class="image"><img src="./static/images/TonyZhao.jpeg" alt="" style="width: 70%; margin-left: auto; margin-right: auto;" /></span>
        </a>
        <span style="font-weight: bold; font-size: 130%;">
          <a href="https://tonyzhaozh.github.io/" target="_blank" style="color: black;">
            Tony Z. Zhao
          </a>
        </span> <br>
        (project co-lead)
      </div>
      <div class="column is-one-fifth is-centered has-text-centered">
        <a href="https://ai.stanford.edu/~cbfinn/" target="_blank" style="border-bottom: none;">
          <span class="image"><img src="./static/images/ChelseaFinn.jpeg" alt="" style="width: 70%; margin-left: auto; margin-right: auto;" /></span>
        </a>
        <span style="font-weight: bold; font-size: 130%;">
          <a href="https://ai.stanford.edu/~cbfinn/" target="_blank" style="color: black;">
            Chelsea Finn
          </a>
        </span> <br>
        (advisor)
      </div>
    </div>
</section> -->
<section class="section">
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Designing egocentric 3D hand pose estimation systems that can perform reliably in complex, 
            real-world scenarios is crucial for downstream applications. Previous approaches using RGB 
            or NIR imagery struggle in challenging conditions: RGB methods are susceptible to lighting 
            variations and obstructions like handwear, while NIR techniques can be disrupted by sunlight 
            or interference from other NIR-equipped devices. To address these limitations, we present ThermoHands, 
            the first benchmark focused on thermal image-based egocentric 3D hand pose estimation, 
            demonstrating the potential of thermal imaging to achieve robust performance under these conditions. 
            The benchmark includes a multi-view and multi-spectral dataset collected from 28 subjects performing 
            hand-object and hand-virtual interactions under diverse scenarios, accurately annotated with 3D hand 
            poses through an automated process. We introduce a new baseline method, TherFormer, utilizing dual 
            transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. 
            Our experimental results highlight TherFormer's leading performance and affirm thermal imaging's 
            effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Data Capture</h2>
    <div class="columns is-centered">
        <div class="column is-two-thirds is-centered has-text-centered">
          <video download controls autoplay loop muted playsinline src="./resources/data_2.mp4" poster="./resources/loading-icon.gif" style="border: 2px solid #ddd; border-radius: 20px; margin: 1.0%;"></video>
        </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          This video shows an example of multi-spectral image data captured by our egocentric ane exocentric platform.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">3D Hand Pose Annotation</h2>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          This video shows an example of 3D hand pose annotations. We show the left (<span style="color: blue;">blue</span>) and right (<span style="color: red;">red</span>) hand 3D joints projected onto
          RGB images. From the same viewpoint, we also visualize the corresponding hand mesh annotation.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-two-thirds is-centered has-text-centered">
        <video download controls autoplay loop muted playsinline src="./resources/annotation_2.mp4" poster="./resources/loading-icon.gif" style="border: 2px solid #ddd; border-radius: 20px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          These figures are selected from different subjects and meticulously cropped to highlight the hands on images. As can be seen, our dataset provides
          high-fidelity and accurate hand pose annotations for various actions.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/gt_supp_exmaples.png" style="width: 105%;">
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Qualitative Results (main)</h2>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          Qualitative results for different spectra under the well-illuminated office (main) setting. 3D hand joints are projected
          onto 2D images for visualization. Ground truth hand pose is shown in <span style="color: #28ff36;">green</span> while the prediction results in <span style="color: blue;">blue</span>.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Object Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/normal_object_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Virtual Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/normal_virtual_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          These figures are selected from different subjects performing various actions. 
          As can be seen, each spectrum can provide reliable testing results, close
          to the ground truth annotations, validating the capability
          of our dataset to support 3D hand pose estimation research
          based on various spectra.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/spectra_normal.png" style="width: 100%;">
      </div>
    </div>
  </div>

</section>


<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Qualitative Results (auxiliary)</h2>

    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          Qualitative results for thermal vs. RGB (NIR) under our four auxiliary settings, 
          including the glove, darkness, sun glare and kitchen scenairos. We show the left (<span style="color: blue;">blue</span>) and right (<span style="color: red;">red</span>) hand 3D joints projected onto
          2D images. 
        </p>
      </div>
    </div>
   
    <!-- Subtitle 2: Glove -->
    <div class="columns is-centered">
      <div class="column is-8">
        <h3 class="title is-4" style="text-align: center; margin-top: 20px;">Glove</h3>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Object Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/glove_object_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Virtual Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/glove_virtual_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          As the hand appearance, including colour and textures, is greatly
          altered by the handwear like gloves in the RGB images, the
          RGB image-based solution fails to accurately estimate the 3D
          hand pose in our examples. In contrast, thermal cameras are
          able to correctly detect hands even under handwear, such as
          gloves by identifying heat transmission patterns.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/spectra_glove.png" style="width: 100%;">
      </div>
    </div>
   
  
    <!-- Subtitle 3: Darkness -->
    <div class="columns is-centered">
      <div class="column is-8">
        <h3 class="title is-4" style="text-align: center; margin-top: 20px;">Darkness</h3>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Object Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/darkness_object_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-one-third has-text-centered">
        <p class="subtitle is-5">Hand-Virtual Interaction</p>
        <video download controls autoplay loop muted playsinline src="./resources/darkness_virtual_2.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #ddd; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          From the RGB images captured in the darkness, we can
          hardly recognize the hand contour even by human eyes. As
          a result, the estimated hand joints either exhibit irregular articulation or deviate significantly from their actual locations.
          Independent of the visible light, thermal cameras are unaffected by the variation of lighting conditions, successfully
          estimating 3D hand pose in the darkness.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/spectra_darkness.png" style="width: 100%;">
      </div>
    </div>
  
   
 
    <!-- Subtitle 4: Sun Glare -->
    <div class="columns is-centered">
      <div class="column is-8">
        <h3 class="title is-4" style="text-align: center; margin-top: 20px;">Sun Glare</h3>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-two-thirds is-centered has-text-centered">
        <video download controls autoplay loop muted playsinline src="./resources/sun_glare_2.mp4" poster="./resources/loading-icon.gif" style="border: 2px solid #ddd; border-radius: 20px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          It can be seen that NIR images are prone
          to interference from the sunlight, which consists of the NIR
          lighting component. In comparison, thermal images are less
          affected and thus yield a better performance under the strong
          sun glare.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/spectra_sunglare.png" style="width: 100%;">
      </div>
    </div>
 
  
    <!-- Subtitle 1: Kitchen -->
    <div class="columns is-centered">
      <div class="column is-8">
        <h3 class="title is-4" style="text-align: center; margin-top: 20px;">Kitchen</h3>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-two-thirds is-centered has-text-centered">
        <video download controls autoplay loop muted playsinline src="./resources/kitchen_2.mp4" poster="./resources/loading-icon.gif" style="border: 2px solid #ddd; border-radius: 20px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <p style="margin: 0 auto; text-align: justify;">
          The thermal camera
          shows better performance than the RGB camera when generalized to an unseen environment. This can be credited to
          the unique attribute of thermal cameras that accentuates the
          hand’s structure via temperature differentials, alleviating the
          effects of background variability. We believe that thermal
          image-based solutions could also generalize well to other
          environments, such as the dining hall and bathroom.
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-8 has-text-centered">
        <img src="./static/images/spectra_kitchen.png" style="width: 100%;">
      </div>
    </div>
  

  </div>
</section>



<!-- <section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Teleoperation</h2>
    <div class="columns is-centered">
      <div class="column is-three-fifths is-centered has-text-centered">
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/mnLVbwxSdNM" title="Mobile ALOHA Robot - Cooking a 3-Course Cantonese Meal" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-three-fifths is-centered has-text-centered">
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/HaaZ8ss-HP4" title="Mobile ALOHA: Your Housekeeping Robot" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-three-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/teleop/teleop_restroom_10x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
  </div>
</section> -->

<!-- 
<section class="section">
  <div class="container">
    <h2 class="title is-2" style="text-align: center;">Robustness and Repeatability</h2>
    <div class="columns is-centered">
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/wipe_wine_9_trials_8x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/take_elevator_5_trials_8x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/use_cabinets_3_pots_8x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/use_cabinets_distractors.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/push_chairs_morning_7_trials_8x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
      <div class="column is-two-fifths is-centered has-text-centered">
        <video controls autoplay loop muted playsinline src="./resources/robustness/push_chairs_night_6_trials_8x_speed.mp4" poster="./resources/loading-icon.gif" style="border: 1px solid #bbb; border-radius: 10px; margin: 1.0%;"></video>
      </div>
    </div>
  </div>
</section>
 -->



<!-- <section class="section">
  <div class="container"> -->
    <!-- Abstract. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Acknowledgements</h2>
        <div class="content has-text-justified">
          <p>
            We thank the Stanford Robotics Center and Steve Cousins for providing facility support for our experiments. We also thank members of Stanford IRIS Lab: Lucy X. Shi and Tian Gao, and members of Stanford REAL Lab: Cheng Chi, Zhenjia Xu, Yihuai Gao, Huy Ha, Zeyi Liu, Xiaomeng Xu, Chuer Pan and Shuran Song, for providing extensive helps for our experiments. We appreciate much photographing by Qingqing Zhao, and feedbacks from and helpful discussions with Karl Pertsch, Boyuan Chen, Ziwen Zhuang, Quan Vuong and Fei Xia. This project is supported by the Boston Dynamics AI Institute and ONR grant N00014-21-1-2685. Zipeng Fu is supported by Stanford Graduate Fellowship. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- <section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="titile">BibTeX</h2>
    <pre><code>@inproceedings{fu2024mobile,
  author    = {Fu, Zipeng and Zhao, Tony Z. and Finn, Chelsea},
  title     = {Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation},
  booktitle = {{Conference on Robot Learning (CoRL)}},
  year      = {2024},
}</code></pre>
  </div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>Page template borrowed from <a href="https://mobile-aloha.github.io/"><span class="dnerf">Nerfies</span></a> and <a href="https://robot-parkour.github.io/"><span class="dnerf">Mobile Aloha</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
